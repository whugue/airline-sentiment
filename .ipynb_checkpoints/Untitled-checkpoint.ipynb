{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Supervised Aspect-Based Sentiment Analysis Models for Use in Airline Opinion Mining Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read-In & Clean Labelled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14640 entries, 0 to 14639\n",
      "Data columns (total 20 columns):\n",
      "_unit_id                        14640 non-null int64\n",
      "_golden                         14640 non-null bool\n",
      "_unit_state                     14640 non-null object\n",
      "_trusted_judgments              14640 non-null int64\n",
      "_last_judgment_at               14584 non-null object\n",
      "airline_sentiment               14640 non-null object\n",
      "airline_sentiment:confidence    14640 non-null float64\n",
      "negativereason                  9178 non-null object\n",
      "negativereason:confidence       10522 non-null float64\n",
      "airline                         14640 non-null object\n",
      "airline_sentiment_gold          40 non-null object\n",
      "name                            14640 non-null object\n",
      "negativereason_gold             32 non-null object\n",
      "retweet_count                   14640 non-null int64\n",
      "text                            14640 non-null object\n",
      "tweet_coord                     1019 non-null object\n",
      "tweet_created                   14640 non-null object\n",
      "tweet_id                        14640 non-null float64\n",
      "tweet_location                  9907 non-null object\n",
      "user_timezone                   9820 non-null object\n",
      "dtypes: bool(1), float64(3), int64(3), object(13)\n",
      "memory usage: 2.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448150</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:35</td>\n",
       "      <td>5.703060e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448153</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:53</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681448156</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 10:01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681448158</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:05</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681448159</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:50</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:14</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  681448150   False   finalized                   3      2/25/15 5:24   \n",
       "1  681448153   False   finalized                   3      2/25/15 1:53   \n",
       "2  681448156   False   finalized                   3     2/25/15 10:01   \n",
       "3  681448158   False   finalized                   3      2/25/15 3:05   \n",
       "4  681448159   False   finalized                   3      2/25/15 5:50   \n",
       "\n",
       "  airline_sentiment  airline_sentiment:confidence negativereason  \\\n",
       "0           neutral                        1.0000            NaN   \n",
       "1          positive                        0.3486            NaN   \n",
       "2           neutral                        0.6837            NaN   \n",
       "3          negative                        1.0000     Bad Flight   \n",
       "4          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason:confidence         airline airline_sentiment_gold  \\\n",
       "0                        NaN  Virgin America                    NaN   \n",
       "1                     0.0000  Virgin America                    NaN   \n",
       "2                        NaN  Virgin America                    NaN   \n",
       "3                     0.7033  Virgin America                    NaN   \n",
       "4                     1.0000  Virgin America                    NaN   \n",
       "\n",
       "         name negativereason_gold  retweet_count  \\\n",
       "0     cairdin                 NaN              0   \n",
       "1    jnardino                 NaN              0   \n",
       "2  yvonnalynn                 NaN              0   \n",
       "3    jnardino                 NaN              0   \n",
       "4    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "   tweet_created      tweet_id tweet_location               user_timezone  \n",
       "0  2/24/15 11:35  5.703060e+17            NaN  Eastern Time (US & Canada)  \n",
       "1  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "2  2/24/15 11:15  5.703010e+17      Lets Play  Central Time (US & Canada)  \n",
       "3  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "4  2/24/15 11:14  5.703010e+17            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = pd.read_csv(\"data/crowdflower/Airline-Sentiment-2-w-AA.csv\")\n",
    "print cf.info()\n",
    "cf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    9178\n",
      "neutral     3099\n",
      "positive    2363\n",
      "Name: airline_sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>negativereason</th>\n",
       "      <th>Bad Flight</th>\n",
       "      <th>Can't Tell</th>\n",
       "      <th>Cancelled Flight</th>\n",
       "      <th>Customer Service Issue</th>\n",
       "      <th>Damaged Luggage</th>\n",
       "      <th>Flight Attendant Complaints</th>\n",
       "      <th>Flight Booking Problems</th>\n",
       "      <th>Late Flight</th>\n",
       "      <th>Lost Luggage</th>\n",
       "      <th>longlines</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>580</td>\n",
       "      <td>1190</td>\n",
       "      <td>847</td>\n",
       "      <td>2910</td>\n",
       "      <td>74</td>\n",
       "      <td>481</td>\n",
       "      <td>529</td>\n",
       "      <td>1665</td>\n",
       "      <td>724</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "negativereason     Bad Flight  Can't Tell  Cancelled Flight  \\\n",
       "airline_sentiment                                             \n",
       "negative                  580        1190               847   \n",
       "\n",
       "negativereason     Customer Service Issue  Damaged Luggage  \\\n",
       "airline_sentiment                                            \n",
       "negative                             2910               74   \n",
       "\n",
       "negativereason     Flight Attendant Complaints  Flight Booking Problems  \\\n",
       "airline_sentiment                                                         \n",
       "negative                                   481                      529   \n",
       "\n",
       "negativereason     Late Flight  Lost Luggage  longlines  \n",
       "airline_sentiment                                        \n",
       "negative                  1665           724        178  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print cf.airline_sentiment.value_counts()\n",
    "pd.crosstab(cf.airline_sentiment, cf.negativereason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Code ABSA Label\n",
    "cf[\"absa\"] = -1 #default\n",
    "cf.ix[cf.airline_sentiment.isin([\"neutral\",\"positive\"]), \"absa\"] = 0 #Positive or Neutral\n",
    "cf.ix[cf.airline_sentiment==\"negative\" & cf.negativereason.isin([\"Cancelled Flight\",\"Late Flight\"]), \"absa\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r\"(?:\\https?\\://)\\S+\", \"\", text) #remove urls\n",
    "    text = re.sub('\\@(\\w+)', \" \", text).replace(\": \",\"\") #remove usernames\n",
    "    text = re.sub('#(\\w+)', \" \", text) #remove hashtags\n",
    "    text = text.replace(\"RT \",\"\") #remove RT Symbols\n",
    "    text = text.replace(\"RT: \",\"\") #remove RT Symbols\n",
    "    text = re.sub(\"[^a-zA-Z,]+\", \" \", text) #remove other non-alpha characters\n",
    "    text = text.strip(\" \") #remove leading and trailing whitespace\n",
    "    \n",
    "    return text\n",
    "\n",
    "def tokenizer(text):\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "    return [x for x in tokenizer.tokenize(preprocess(text)) if len(x)>=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Read In CrowdFlower Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(decode_error=\"ignore\", ngram_range=(1,1), tokenizer=tokenizer)\n",
    "\n",
    "X0 = [\"This is the first document. HaHa!\"]\n",
    "X = [\"Second Document Document Here. Contains words not in first.\"]\n",
    "\n",
    "print tokenizer(X0[0])\n",
    "print tokenizer(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X0 = vectorizer.fit_transform(X0)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = [\"willhuguenin is not in the vocabulary. Becuz the vocab is lame :(\"]\n",
    "print tokenizer(sentence[0])\n",
    "#text_X = vectorizer.transform(text)\n",
    "#print text_X.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_X = vectorizer.transform(sentence)\n",
    "print new_X.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_count_model(classifier, train, test, sws, binary):\n",
    "    vectorizer = CountVectorizer(decode_error=\"ignore\", ngram_range=(1,1), tokenizer=tokenize, binary=binary)\n",
    "    \n",
    "    vectorizer.fit(train[\"text\"])\n",
    "    \n",
    "    train_X = vectorizer.transform(train[\"text\"])\n",
    "    test_X = vectorizer.transform(test[\"text\"])\n",
    "    \n",
    "    train_y = train[\"sentiment\"]\n",
    "    test_y = test[\"sentiment\"]\n",
    "    \n",
    "    clf = classifier.fit(train_X, train_y)\n",
    "    \n",
    "    #print \"Confusion Matrix: \"\n",
    "    #print confusion_matrix(test_y, clf.predict(test_X))\n",
    "    \n",
    "    accuracy = accuracy_score(test_y, clf.predict(test_X))\n",
    "    features = zip(vectorizer.get_feature_names(), clf.coef_[0])\n",
    "    top10_features = sorted(features, reverse=True, key=lambda x: x[1])[:10]\n",
    "    \n",
    "    print \"Accuracy: \"+str(accuracy)\n",
    "    \n",
    "    return [accuracy, [x[0] for x in top10_features]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
